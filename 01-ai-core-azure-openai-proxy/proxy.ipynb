{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Install AI Core Python SDK"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1189875.82s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
                        "Requirement already satisfied: ai-api-client-sdk in /opt/homebrew/lib/python3.11/site-packages (1.27.0)\n",
                        "Requirement already satisfied: aenum~=3.1 in /opt/homebrew/lib/python3.11/site-packages (from ai-api-client-sdk) (3.1.12)\n",
                        "Requirement already satisfied: pyhumps~=3.0 in /opt/homebrew/lib/python3.11/site-packages (from ai-api-client-sdk) (3.8.0)\n",
                        "Requirement already satisfied: requests<3.0 in /opt/homebrew/lib/python3.11/site-packages (from ai-api-client-sdk) (2.31.0)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk) (3.1.0)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk) (3.4)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk) (2.0.3)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0->ai-api-client-sdk) (2023.5.7)\n"
                    ]
                }
            ],
            "source": [
                "!pip install ai-api-client-sdk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import requests\n",
                "import time\n",
                "import yaml\n",
                "from IPython.display import clear_output\n",
                "from pprint import pprint\n",
                "\n",
                "from ai_api_client_sdk.ai_api_v2_client import AIAPIV2Client\n",
                "from ai_api_client_sdk.models.status import Status\n",
                "from ai_api_client_sdk.models.target_status import TargetStatus\n",
                "from ai_api_client_sdk.models.parameter_binding import ParameterBinding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "aic_service_key_path = \"./resources/aic_service_key.json\"\n",
                "git_setup_file_path = \"./resources/git_setup.json\"\n",
                "docker_secret_file_path = \"./resources/docker_secret.json\"\n",
                "env_file_path = \"./resources/env.json\"\n",
                "resource_group = \"azure-openai-aicore\"\n",
                "serving_workflow_file = \"./scenario/proxy.yaml\"\n",
                "connection_name = \"default\"\n",
                "path_prefix = \"app\""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Connect to your AI Core instance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(aic_service_key_path) as ask:\n",
                "    aic_service_key = json.load(ask)\n",
                "\n",
                "# AI API client that talks to the AI Core instance.\n",
                "ai_api_client = AIAPIV2Client(\n",
                "    base_url = aic_service_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\", # The present AI API version is 2\n",
                "    auth_url=  aic_service_key[\"url\"] + \"/oauth/token\",\n",
                "    client_id = aic_service_key[\"clientid\"],\n",
                "    client_secret = aic_service_key[\"clientsecret\"]\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Onboard the Git repository that contains the templates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AIAPIServerException",
                    "evalue": "Failed to post /admin/repositories: Repository is already onboarded \n Status Code: 409, Request ID:None",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAIAPIServerException\u001b[0m                      Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[110], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \t\tsetup_json \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(gs)\n\u001b[1;32m      4\u001b[0m repo_json \u001b[39m=\u001b[39m setup_json[\u001b[39m\"\u001b[39m\u001b[39mrepo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m response \u001b[39m=\u001b[39m ai_api_client\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m      7\u001b[0m \t\tpath\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/admin/repositories\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m \t\tbody\u001b[39m=\u001b[39;49m{\n\u001b[1;32m      9\u001b[0m \t\t\t\t\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: repo_json[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     10\u001b[0m \t\t\t\t\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m: repo_json[\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     11\u001b[0m \t\t\t\t\u001b[39m\"\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m\"\u001b[39;49m: repo_json[\u001b[39m\"\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     12\u001b[0m \t\t\t\t\u001b[39m\"\u001b[39;49m\u001b[39mpassword\u001b[39;49m\u001b[39m\"\u001b[39;49m: repo_json[\u001b[39m\"\u001b[39;49m\u001b[39mpassword\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     13\u001b[0m \t\t}\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_api_client_sdk/helpers/rest_client.py:146\u001b[0m, in \u001b[0;36mRestClient.post\u001b[0;34m(self, path, body, headers, resource_group)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, path: \u001b[39mstr\u001b[39m, body: Dict[\u001b[39mstr\u001b[39m, Union[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, headers: Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    119\u001b[0m          resource_group: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m    120\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a POST request to the server.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[39m    :param path: path of the endpoint the request should be sent to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m    :rtype: dict\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_request(\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m, path\u001b[39m=\u001b[39;49mpath, body_json\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders, resource_group\u001b[39m=\u001b[39;49mresource_group)\n",
                        "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ai_api_client_sdk/helpers/rest_client.py:110\u001b[0m, in \u001b[0;36mRestClient._handle_request\u001b[0;34m(self, method, path, params, body_json, headers, resource_group)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[39mraise\u001b[39;00m AIAPIPreconditionFailedException(description\u001b[39m=\u001b[39merror_description, error_message\u001b[39m=\u001b[39merror_message,\n\u001b[1;32m    107\u001b[0m                                                error_code\u001b[39m=\u001b[39merror_code, request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    108\u001b[0m                                                details\u001b[39m=\u001b[39merror_details)\n\u001b[1;32m    109\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         \u001b[39mraise\u001b[39;00m AIAPIServerException(status_code\u001b[39m=\u001b[39mstatus_code, description\u001b[39m=\u001b[39merror_description,\n\u001b[1;32m    111\u001b[0m                                    error_message\u001b[39m=\u001b[39merror_message, error_code\u001b[39m=\u001b[39merror_code, request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    112\u001b[0m                                    details\u001b[39m=\u001b[39merror_details)\n\u001b[1;32m    113\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m AIAPIServerException(description\u001b[39m=\u001b[39merror_description, error_message\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mtext,\n\u001b[1;32m    115\u001b[0m                                status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code)\n",
                        "\u001b[0;31mAIAPIServerException\u001b[0m: Failed to post /admin/repositories: Repository is already onboarded \n Status Code: 409, Request ID:None"
                    ]
                }
            ],
            "source": [
                "with open(git_setup_file_path) as gs:\n",
                "\t\tsetup_json = json.load(gs)\n",
                "\n",
                "repo_json = setup_json[\"repo\"]\n",
                "\n",
                "response = ai_api_client.rest_client.post(\n",
                "\t\tpath=\"/admin/repositories\",\n",
                "\t\tbody={\n",
                "\t\t\t\t\"name\": repo_json[\"name\"],\n",
                "\t\t\t\t\"url\": repo_json[\"url\"],\n",
                "\t\t\t\t\"username\": repo_json[\"username\"],\n",
                "\t\t\t\t\"password\": repo_json[\"password\"]\n",
                "\t\t}\n",
                ")\n",
                "print(response)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Register an application"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "app_json = setup_json[\"app\"]\n",
                "response = ai_api_client.rest_client.post(\n",
                "\t\tpath=\"/admin/applications\",\n",
                "\t\tbody={\n",
                "\t\t\t\t\"applicationName\": app_json[\"applicationName\"],\n",
                "\t\t\t\t\"repositoryUrl\": app_json[\"repositoryUrl\"],\n",
                "\t\t\t\t\"revision\": app_json[\"revision\"],\n",
                "\t\t\t\t\"path\": app_json[\"path\"]\n",
                "\t\t}\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4 Docker Hub (optional)\n",
                "#### 4.1 Register Docker secret on SAP BTP, AI Core (optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'data': {'.dockerconfigjson': '{\"auths\": {\"docker.io\": {\"username\": '\n",
                        "                               '\"<kuhnlinhsa>\", \"password\": '\n",
                        "                               '\"<dckr_pat_3-5v34HewiyJWPUQpw3G8UwHFgc>\"}}}'},\n",
                        " 'name': 'docker-credentials'}\n",
                        "{'message': 'secret has been created'}\n"
                    ]
                }
            ],
            "source": [
                "with open(docker_secret_file_path) as dsf:\n",
                "    docker_secret = json.load(dsf)\n",
                "\n",
                "pprint(docker_secret)\n",
                "\n",
                "response = ai_api_client.rest_client.post(\n",
                "    path=\"/admin/dockerRegistrySecrets\",\n",
                "    body={\n",
                "        \"name\": docker_secret[\"name\"],\n",
                "        \"data\": docker_secret[\"data\"]\n",
                "    }\n",
                ")\n",
                "print(response)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 4.2 Build and push Docker image (optional)\n",
                "```\n",
                "$ cd proxy\n",
                "$ docker build -t {DOCKER_USERNAME}/azure-openai-proxy .\n",
                "$ docker push {DOCKER_USERNAME}/azure-openai-proxy\n",
                "```\n",
                "\n",
                "THROUGH THE DOCKER CLI.  \n",
                "See: https://developers.sap.com/tutorials/ai-core-aiapi-clientsdk-workflows.html#f824a41d-efe8-4883-8238-caef4ac5f789"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Create a resource group"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'resource_group_id': 'azure-openai-aicore',\n",
                            " 'tenant_id': 'f9a20f97-85f0-4e19-b9e7-c2fa39ff4643',\n",
                            " 'zone_id': 'f9a20f97-85f0-4e19-b9e7-c2fa39ff4643'}"
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ai_api_client.rest_client.post(\n",
                "    path=\"/admin/resourceGroups\",\n",
                "    body={\n",
                "        \"resourceGroupId\": resource_group\n",
                "    }\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Create configuration to serve the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'ai_core_client' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[113], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m DOCKER_NAMESPACE \u001b[39m=\u001b[39m env_val[\u001b[39m\"\u001b[39m\u001b[39mDOCKER_NAMESPACE\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[39m# No modification required in below snippet\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m response \u001b[39m=\u001b[39m ai_core_client\u001b[39m.\u001b[39mconfiguration\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     51\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mazure-proxy-serve\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m     scenario_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mazure-openai-proxy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m     executable_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mazure-openai-proxy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m     input_artifact_bindings \u001b[39m=\u001b[39m [],\n\u001b[1;32m     55\u001b[0m     parameter_bindings \u001b[39m=\u001b[39m [\n\u001b[1;32m     56\u001b[0m         ParameterBinding(key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_BASE\u001b[39m\u001b[39m\"\u001b[39m, value \u001b[39m=\u001b[39m OPENAI_API_BASE),\n\u001b[1;32m     57\u001b[0m         ParameterBinding(key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m, value \u001b[39m=\u001b[39m OPENAI_API_KEY), \n\u001b[1;32m     58\u001b[0m         ParameterBinding(key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDOCKER_NAMESPACE\u001b[39m\u001b[39m\"\u001b[39m, value \u001b[39m=\u001b[39m DOCKER_NAMESPACE)\n\u001b[1;32m     59\u001b[0m     ],\n\u001b[1;32m     60\u001b[0m     resource_group \u001b[39m=\u001b[39m resource_group_id\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     64\u001b[0m serve_config_resp \u001b[39m=\u001b[39m response\n\u001b[1;32m     65\u001b[0m \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'ai_core_client' is not defined"
                    ]
                }
            ],
            "source": [
                "# # Create another AI API client to use different base url.\n",
                "# ai_api_v2_client = AIAPIV2Client(\n",
                "#     base_url=aic_service_key[\"serviceurls\"][\"AI_API_URL\"] + \"/v2/lm\",\n",
                "#     auth_url=aic_service_key[\"url\"] + \"/oauth/token\",\n",
                "#     client_id=aic_service_key[\"clientid\"],\n",
                "#     client_secret=aic_service_key[\"clientsecret\"],\n",
                "#     resource_group=resource_group)\n",
                "\n",
                "# with open(serving_workflow_file) as swf:\n",
                "#     serving_workflow = yaml.safe_load(swf)\n",
                "\n",
                "# print('Step 1')\n",
                "\n",
                "# scenario_id = serving_workflow[\"metadata\"][\"labels\"][\"scenarios.ai.sap.com/id\"]\n",
                "# executable_name = serving_workflow[\"metadata\"][\"name\"]\n",
                "\n",
                "# print('Step 2',executable_name)\n",
                "\n",
                "# with open(env_file_path) as efp:\n",
                "#     environment_values = json.load(efp)\n",
                "\n",
                "# parameter_bindings = [ParameterBinding(key=key, value=value) for key, value in environment_values.items()]\n",
                "\n",
                "\n",
                "# serve_configuration = {\n",
                "#     \"name\": f\"{resource_group}-serve\",\n",
                "#     \"scenario_id\": scenario_id,\n",
                "#     \"executable_id\": executable_name,\n",
                "#     \"parameter_bindings\": parameter_bindings,\n",
                "#     \"input_artifact_bindings\": []\n",
                "# }\n",
                "\n",
                "# print('Step 3',serve_configuration)\n",
                "\n",
                "# serve_config_resp = ai_api_v2_client.configuration.create(**serve_configuration)\n",
                "\n",
                "# print('Step 4')\n",
                "\n",
                "# assert serve_config_resp.message == \"Configuration created\"\n",
                "\n",
                "# pprint(vars(serve_config_resp))\n",
                "# print(\"configuration for serving the model created\")\n",
                "with open(env_file_path) as efp:\n",
                "    env_val = json.load(efp)\n",
                "\n",
                "OPENAI_API_BASE = env_val[\"OPENAI_API_BASE\"]\n",
                "OPENAI_API_KEY = env_val[\"OPENAI_API_KEY\"]\n",
                "DOCKER_NAMESPACE = env_val[\"DOCKER_NAMESPACE\"]\n",
                "# No modification required in below snippet\n",
                "response = ai_core_client.configuration.create(\n",
                "    name = \"azure-proxy-serve\",\n",
                "    scenario_id = \"azure-openai-proxy\",\n",
                "    executable_id = \"azure-openai-proxy\",\n",
                "    input_artifact_bindings = [],\n",
                "    parameter_bindings = [\n",
                "        ParameterBinding(key = \"OPENAI_API_BASE\", value = OPENAI_API_BASE),\n",
                "        ParameterBinding(key = \"OPENAI_API_KEY\", value = OPENAI_API_KEY), \n",
                "        ParameterBinding(key = \"DOCKER_NAMESPACE\", value = DOCKER_NAMESPACE)\n",
                "    ],\n",
                "    resource_group = resource_group_id\n",
                ")\n",
                "\n",
                "\n",
                "serve_config_resp = response\n",
                "print(response.__dict__)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7. Actually serve the proxy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'serve_config_resp' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deployment_resp \u001b[39m=\u001b[39m ai_api_v2_client\u001b[39m.\u001b[39mdeployment\u001b[39m.\u001b[39mcreate(serve_config_resp\u001b[39m.\u001b[39mid)\n\u001b[1;32m      2\u001b[0m pprint(\u001b[39mvars\u001b[39m(deployment_resp))\n\u001b[1;32m      4\u001b[0m \u001b[39m# Poll deployment status.\u001b[39;00m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'serve_config_resp' is not defined"
                    ]
                }
            ],
            "source": [
                "deployment_resp = ai_api_v2_client.deployment.create(serve_config_resp.id)\n",
                "pprint(vars(deployment_resp))\n",
                "\n",
                "# Poll deployment status.\n",
                "status = None\n",
                "while status != Status.RUNNING and status != Status.DEAD:\n",
                "    time.sleep(5)\n",
                "    clear_output(wait=True)\n",
                "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
                "    status = deployment.status\n",
                "    print(\"...... deployment status ......\", flush=True)\n",
                "    print(deployment.status)\n",
                "    pprint(deployment.status_details)\n",
                "\n",
                "    if deployment.status == Status.RUNNING:\n",
                "        print(f\"Deployment with {deployment_resp.id} complete!\")\n",
                "\n",
                "# Allow some time for deployment URL to get ready.\n",
                "time.sleep(10)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8. Do an inference request"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "endpoint = f\"{deployment.deployment_url}/v2/envs\"\n",
                "headers = {\"Authorization\": ai_api_v2_client.rest_client.get_token(),\n",
                "           \"ai-resource-group\": resource_group,\n",
                "           \"Content-Type\": \"application/json\"}\n",
                "response = requests.get(endpoint, headers=headers)\n",
                "\n",
                "legacy_davinci = False # set True if you have a davinci model deployment on Azure OpenAI Services\n",
                "if legacy_davinci:\n",
                "    body = {\n",
                "        \"engine\": \"<YOUR ENGINE>\", # include your davinci engine from a deployment of an Azure OpenAI services model\n",
                "        \"prompt\": \"Classify the following news article into 1 of the following categories: categories: [Business, Tech, Politics, Sport, Entertainment]\\n\\nnews article: Donna Steffensen Is Cooking Up a New Kind of Perfection. The Internet’s most beloved cooking guru has a buzzy new book and a fresh new perspective:\\n\\nClassified category:\",\n",
                "        \"max_tokens\": 60,\n",
                "        \"temperature\": 0,\n",
                "        \"frequency_penalty\": 0,\n",
                "        \"presence_penalty\": 0,\n",
                "        \"top_p\": 1,\n",
                "        \"best_of\": 1,\n",
                "        \"stop\": \"null\"\n",
                "    }\n",
                "    endpoint = f\"{deployment.deployment_url}/v2/completion\"\n",
                "else:\n",
                "    body = {\n",
                "        \"engine\": \"<YOUR ENGINE>\", # include your engine from a deployment of an Azure OpenAI services model\n",
                "        \"prompt\": \"Classify the following news article into 1 of the following categories: categories: [Business, Tech, Politics, Sport, Entertainment]\\n\\nnews article: Donna Steffensen Is Cooking Up a New Kind of Perfection. The Internet’s most beloved cooking guru has a buzzy new book and a fresh new perspective:\\n\\nClassified category:\",\n",
                "        \"max_tokens\": 60,\n",
                "        \"temperature\": 0,\n",
                "        \"frequency_penalty\": 0,\n",
                "        \"presence_penalty\": 0,\n",
                "        \"stop\": \"null\"\n",
                "    }\n",
                "    endpoint = f\"{deployment.deployment_url}/v2/chat-completion\"\n",
                "\n",
                "headers = {\"Authorization\": ai_api_v2_client.rest_client.get_token(),\n",
                "           \"ai-resource-group\": resource_group,\n",
                "           \"Content-Type\": \"application/json\"}\n",
                "response = requests.post(endpoint, headers=headers, json=body)\n",
                "\n",
                "print(\"Inference result:\", response.json())\n",
                "pprint(vars(response))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9. Kill deployment (optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "delete_resp = ai_api_v2_client.deployment.modify(deployment_resp.id,\n",
                "                                                 target_status=TargetStatus.STOPPED)\n",
                "status = None\n",
                "while status != Status.STOPPED:\n",
                "    time.sleep(5)\n",
                "    clear_output(wait=True)\n",
                "    deployment = ai_api_v2_client.deployment.get(deployment_resp.id)\n",
                "    status = deployment.status\n",
                "    print(\"...... killing deployment ......\", flush=True)\n",
                "    print(f\"Deployment status: {deployment.status}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
